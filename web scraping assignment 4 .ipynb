{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce646066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de2d0f1",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3002e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver.exe\")\n",
    "time.sleep(4)\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a72cb8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[15]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[24]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[25]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[35]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[36]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[42]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[43]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Shake It Off\"[50]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                               \"Shape of You\"[15]   \n",
       "4    5.                                  \"Bath Song\"[17]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                                \"Uptown Funk\"[24]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[25]   \n",
       "9   10.                          \"Wheels on the Bus\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                       \"Roar\"[35]   \n",
       "15  16.                             \"Counting Stars\"[36]   \n",
       "16  17.                                     \"Axel F\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.                                 \"Dark Horse\"[41]   \n",
       "21  22.                                      \"Faded\"[42]   \n",
       "22  23.                             \"Girls Like You\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29  30.                               \"Shake It Off\"[50]   \n",
       "\n",
       "                                           Artist        Upload_date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  11.83  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.02  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.54  \n",
       "3                                      Ed Sheeran   January 30, 2017   5.86  \n",
       "4                      Cocomelon – Nursery Rhymes        May 2, 2018   5.81  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.71  \n",
       "6                                       ChuChu TV      March 6, 2014   5.04  \n",
       "7                                     Mark Ronson  November 19, 2014   4.77  \n",
       "8                                     Miroshka TV  February 27, 2018   4.74  \n",
       "9                      Cocomelon – Nursery Rhymes       May 24, 2018   4.69  \n",
       "10                                            Psy      July 15, 2012   4.62  \n",
       "11                                     Get Movies   January 31, 2012   4.52  \n",
       "12                                      El Chombo      April 5, 2018   4.15  \n",
       "13                                       Maroon 5   January 14, 2015   3.79  \n",
       "14                                     Katy Perry  September 5, 2013   3.69  \n",
       "15                                    OneRepublic       May 31, 2013   3.69  \n",
       "16                                     Crazy Frog      June 16, 2009   3.63  \n",
       "17                                  Justin Bieber   October 22, 2015   3.61  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.52  \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   3.44  \n",
       "20                                     Katy Perry  February 20, 2014   3.40  \n",
       "21                                    Alan Walker   December 3, 2015   3.38  \n",
       "22                                       Maroon 5       May 31, 2018   3.35  \n",
       "23                                      Passenger      July 25, 2012   3.35  \n",
       "24                                        Shakira       June 4, 2010   3.34  \n",
       "25                                     Ed Sheeran   November 9, 2017   3.31  \n",
       "26                               Enrique Iglesias     April 11, 2014   3.30  \n",
       "27                                    Major Lazer     March 22, 2015   3.29  \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.24  \n",
       "29                                   Taylor Swift    August 18, 2014   3.23  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating blank list\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "\n",
    "#Scraping Rank\n",
    "rank=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "1\n",
    "#Scraping Name\n",
    "name=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping Artist\n",
    "artist=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "for i in artist:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Views\n",
    "views=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "for i in views:\n",
    "    Views.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Upload_date\n",
    "upload_date=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "for i in upload_date:\n",
    "    Upload_date.append(i.text)\n",
    "    \n",
    "Youtube_viewed=pd.DataFrame({})\n",
    "Youtube_viewed['Rank']=Rank\n",
    "Youtube_viewed['Name']=Name\n",
    "Youtube_viewed['Artist']=Artist\n",
    "Youtube_viewed['Upload_date']=Upload_date\n",
    "Youtube_viewed['Views']=Views\n",
    "Youtube_viewed\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3344387",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858bbab2",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e47778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver.exe\")\n",
    "time.sleep(4)\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "time.sleep(4)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2336f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#getting the specified url\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "#Getting url for international fixture and clicking on it\n",
    "Options_btn = driver.find_element(By.XPATH , '//div[@class=\"collapse navbar-collapse\"]/ul/li[2]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    driver.find_element(By.XPATH , '//button[@class=\"cookie__accept btn btn-primary\"]').click()\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "more_fixtures = driver.find_element(By.XPATH , '//button[@class=\"match-btn btn-red d-flex align-items-center justify-content-center mx-auto mt-3\"]').click()\n",
    "#Infix_btn = driver.find_element(By.XPATH ,\"//a[@class='navigation__link navigation__link--in-drop-down']\").click()\n",
    "time.sleep(3)\n",
    "\n",
    "#Creating empty list\n",
    "Match_title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []\n",
    "\n",
    "#Scraping data of match title\n",
    "for i in driver.find_elements(By.XPATH ,'//span[@class=\"matchOrderText ng-binding ng-scope\"]'):\n",
    "    i = i.text[:-2]\n",
    "    Match_title.append(i)\n",
    "    \n",
    "#Scraping data of Place\n",
    "for i in driver.find_elements(By.XPATH ,'//div[@class=\"fix-place ng-binding ng-scope\"]'):\n",
    "    i = i.text\n",
    "    x = i.split('-')\n",
    "    Place.append(x[1])\n",
    " \n",
    "#scraping series data\n",
    "series = driver.find_elements(By.XPATH ,'//span[@class=\"ng-binding\"]')\n",
    "\n",
    "for i in series:\n",
    "    try:\n",
    "        Series.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Series.append('-')\n",
    "\n",
    "\n",
    "#Scraping data of dates\n",
    "\n",
    "dates = driver.find_elements(By.XPATH ,'//div[@class=\"match-card-left match-schedule\"]')\n",
    "for i in dates:\n",
    "    try:\n",
    "        Date.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Date.append('-')\n",
    "\n",
    "#Scraping time data\n",
    "times = driver.find_elements(By.XPATH ,'//div[@class=\"match-card-right match-schedule \"]')\n",
    "for i in times:\n",
    "    try:\n",
    "        Time.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Time.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24e88405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH ODI SERIES 2022-23</td>\n",
       "      <td>Zahur Ahmed Chowdhury Stadium, Chattogram</td>\n",
       "      <td>10 DEC 2022</td>\n",
       "      <td>11:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>DY Patil Stadium, NAVI MUMBAI</td>\n",
       "      <td>11 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH TEST SERIES 2022-23</td>\n",
       "      <td>Zahur Ahmed Chowdhury Stadium, Chattogram</td>\n",
       "      <td>14 DEC 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>Brabourne</td>\n",
       "      <td>14 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>Brabourne</td>\n",
       "      <td>17 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>Brabourne</td>\n",
       "      <td>20 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH TEST SERIES 2022-23</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka</td>\n",
       "      <td>22 DEC 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>3 JAN 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>5 JAN 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>Saurashtra Cricket Association Stadium, Rajkot</td>\n",
       "      <td>7 JAN 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>Barsapara Cricket Stadium, Guwahati</td>\n",
       "      <td>10 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>Eden Gardens, Kolkata</td>\n",
       "      <td>12 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>Greenfield International Stadium, Thiruvanant...</td>\n",
       "      <td>15 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>NEW ZEALAND TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>Rajiv Gandhi International Stadium, Hyderabad</td>\n",
       "      <td>18 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>NEW ZEALAND TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>Shaheed Veer Narayan Singh International Cric...</td>\n",
       "      <td>21 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>NEW ZEALAND TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>Holkar Cricket Stadium, Indore</td>\n",
       "      <td>24 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match Title                                        Series  \\\n",
       "0      3rd ODI   INDIA TOUR OF BANGLADESH ODI SERIES 2022-23   \n",
       "1     2nd T20I            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "2     1st Test  INDIA TOUR OF BANGLADESH TEST SERIES 2022-23   \n",
       "3     3rd T20I            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "4     4th T20I            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "5     5th T20I            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "6     2nd Test  INDIA TOUR OF BANGLADESH TEST SERIES 2022-23   \n",
       "7     1st T20I    SRI LANKA TOUR OF INDIA T20 SERIES 2022-23   \n",
       "8     2nd T20I    SRI LANKA TOUR OF INDIA T20 SERIES 2022-23   \n",
       "9     3rd T20I    SRI LANKA TOUR OF INDIA T20 SERIES 2022-23   \n",
       "10     1st ODI    SRI LANKA TOUR OF INDIA ODI SERIES 2022-23   \n",
       "11     2nd ODI    SRI LANKA TOUR OF INDIA ODI SERIES 2022-23   \n",
       "12     3rd ODI    SRI LANKA TOUR OF INDIA ODI SERIES 2022-23   \n",
       "13     1st ODI  NEW ZEALAND TOUR OF INDIA ODI SERIES 2022-23   \n",
       "14     2nd ODI  NEW ZEALAND TOUR OF INDIA ODI SERIES 2022-23   \n",
       "15     3rd ODI  NEW ZEALAND TOUR OF INDIA ODI SERIES 2022-23   \n",
       "\n",
       "                                                Place         Date  \\\n",
       "0           Zahur Ahmed Chowdhury Stadium, Chattogram  10 DEC 2022   \n",
       "1                       DY Patil Stadium, NAVI MUMBAI  11 DEC 2022   \n",
       "2           Zahur Ahmed Chowdhury Stadium, Chattogram  14 DEC 2022   \n",
       "3                                          Brabourne   14 DEC 2022   \n",
       "4                                          Brabourne   17 DEC 2022   \n",
       "5                                          Brabourne   20 DEC 2022   \n",
       "6        Shere Bangla National Stadium, Mirpur, Dhaka  22 DEC 2022   \n",
       "7                            Wankhede Stadium, Mumbai   3 JAN 2023   \n",
       "8       Maharashtra Cricket Association Stadium, Pune   5 JAN 2023   \n",
       "9      Saurashtra Cricket Association Stadium, Rajkot   7 JAN 2023   \n",
       "10                Barsapara Cricket Stadium, Guwahati  10 JAN 2023   \n",
       "11                              Eden Gardens, Kolkata  12 JAN 2023   \n",
       "12   Greenfield International Stadium, Thiruvanant...  15 JAN 2023   \n",
       "13      Rajiv Gandhi International Stadium, Hyderabad  18 JAN 2023   \n",
       "14   Shaheed Veer Narayan Singh International Cric...  21 JAN 2023   \n",
       "15                     Holkar Cricket Stadium, Indore  24 JAN 2023   \n",
       "\n",
       "            Time  \n",
       "0   11:30 AM IST  \n",
       "1    7:00 PM IST  \n",
       "2    9:30 AM IST  \n",
       "3    7:00 PM IST  \n",
       "4    7:00 PM IST  \n",
       "5    7:00 PM IST  \n",
       "6    9:30 AM IST  \n",
       "7    7:30 PM IST  \n",
       "8    7:30 PM IST  \n",
       "9    7:30 PM IST  \n",
       "10   1:30 PM IST  \n",
       "11   1:30 PM IST  \n",
       "12   1:30 PM IST  \n",
       "13   1:30 PM IST  \n",
       "14   1:30 PM IST  \n",
       "15   1:30 PM IST  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe\n",
    "BCCI=pd.DataFrame({})\n",
    "BCCI['Match Title'] = Match_title\n",
    "BCCI['Series'] = Series\n",
    "BCCI['Place'] = Place\n",
    "BCCI['Date'] = Date\n",
    "BCCI['Time'] = Time\n",
    "\n",
    "#Printing data frame\n",
    "BCCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "891b3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ce8d9",
   "metadata": {},
   "source": [
    "#### 3. Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/\n",
    "#### You need to find following details:\n",
    "#### A) Name\n",
    "#### B) Description\n",
    "#### Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80eb8e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Exception</th>\n",
       "      <th>Description of Exception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the eleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidElementStateException</td>\n",
       "      <td>It occurs when command can’t be finished when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an aler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver doesn’t sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name of Exception  \\\n",
       "0             ElementNotVisibleException   \n",
       "1          ElementNotSelectableException   \n",
       "2                 NoSuchElementException   \n",
       "3                   NoSuchFrameException   \n",
       "4                NoAlertPresentException   \n",
       "5                  NoSuchWindowException   \n",
       "6         StaleElementReferenceException   \n",
       "7               SessionNotFoundException   \n",
       "8                       TimeoutException   \n",
       "9                     WebDriverException   \n",
       "10             ConnectionClosedException   \n",
       "11      ElementClickInterceptedException   \n",
       "12       ElementNotInteractableException   \n",
       "13              ErrorInResponseException   \n",
       "14   ErrorHandler.UnknownServerException   \n",
       "15          ImeActivationFailedException   \n",
       "16              ImeNotAvailableException   \n",
       "17          InsecureCertificateException   \n",
       "18              InvalidArgumentException   \n",
       "19          InvalidCookieDomainException   \n",
       "20           InvalidCoordinatesException   \n",
       "21          InvalidElementStateException   \n",
       "22             InvalidSessionIdException   \n",
       "23        InvalidSwitchToTargetException   \n",
       "24                   JavascriptException   \n",
       "25                         JsonException   \n",
       "26              NoSuchAttributeException   \n",
       "27        MoveTargetOutOfBoundsException   \n",
       "28                NoSuchContextException   \n",
       "29                 NoSuchCookieException   \n",
       "30                     NotFoundException   \n",
       "31           RemoteDriverServerException   \n",
       "32                   ScreenshotException   \n",
       "33            SessionNotCreatedException   \n",
       "34            UnableToSetCookieException   \n",
       "35            UnexpectedTagNameException   \n",
       "36               UnhandledAlertException   \n",
       "37       UnexpectedAlertPresentException   \n",
       "38                UnknownMethodException   \n",
       "39           UnreachableBrowserException   \n",
       "40           UnsupportedCommandException   \n",
       "\n",
       "                             Description of Exception  \n",
       "0    This type of Selenium exception occurs when a...  \n",
       "1    This Selenium exception occurs when an elemen...  \n",
       "2    This Exception occurs if an element could not...  \n",
       "3    This Exception occurs if the frame target to ...  \n",
       "4    This Exception occurs when you switch to no p...  \n",
       "5    This Exception occurs if the window target to...  \n",
       "6    This Selenium exception occurs happens when t...  \n",
       "7    The WebDriver is acting after you quit the br...  \n",
       "8    Thrown when there is not enough time for a co...  \n",
       "9    This Exception takes place when the WebDriver...  \n",
       "10   This type of Exception takes place when there...  \n",
       "11   The command may not be completed as the eleme...  \n",
       "12   This Selenium exception is thrown when any el...  \n",
       "13   This happens while interacting with the Firef...  \n",
       "14   Exception is used as a placeholder in case if...  \n",
       "15   This expectation will occur when IME engine a...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17   Navigation made the user agent to hit a certi...  \n",
       "18   It occurs when an argument does not belong to...  \n",
       "19   This happens when you try to add a cookie und...  \n",
       "20   This type of Exception matches an interacting...  \n",
       "21   It occurs when command can’t be finished when...  \n",
       "22   This Exception took place when the given sess...  \n",
       "23   This occurs when the frame or window target t...  \n",
       "24   This issue occurs while executing JavaScript ...  \n",
       "25   It occurs when you afford to get the session ...  \n",
       "26   This kind of Exception occurs when the attrib...  \n",
       "27   It takes place if the target provided to the ...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29   This Exception occurs when no cookie matching...  \n",
       "30   This Exception is a subclass of WebDriverExce...  \n",
       "31   This Selenium exception is thrown when the se...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33   It happens when a new session could not be su...  \n",
       "34   This occurs if a driver is unable to set a co...  \n",
       "35   Happens if a support class did not get a web ...  \n",
       "36   This expectation occurs when there is an aler...  \n",
       "37   It occurs when there is the appearance of an ...  \n",
       "38   This Exception happens when the requested com...  \n",
       "39   This Exception occurs only when the browser i...  \n",
       "40   This occurs when remote WebDriver doesn’t sen...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connecting to the web driver\n",
    "driver=driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver.exe\")\n",
    "\n",
    "#getting the specified url\n",
    "url = \"https://www.guru99.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(10)\n",
    "\n",
    "#Going to search bar and searching for selenium exception\n",
    "# ser_button = driver.find_element(By.XPATH ,'//span[@class=\"kadence-svg-iconset\"]')\n",
    "# ser_button.click()\n",
    "# print(\"Search button 1 clicked\")\n",
    "\n",
    "# time.sleep(3)\n",
    "\n",
    "# ser_bar  = driver.find_element(By.XPATH ,'//td[@class=\"gsc-input\"]')\n",
    "# ser_bar.send_keys(\"selenium exception handling\")\n",
    "\n",
    "\n",
    "ser_but = driver.find_element(By.XPATH ,'//div[@class=\"srch\"]/span[8]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "#Url of selenium exception handling page\n",
    "urls = driver.find_elements(By.XPATH ,'//td[@class=\"responsivetable\"]/a')\n",
    "page_url = urls[69].get_attribute(\"href\")\n",
    "\n",
    "driver.get(page_url)\n",
    "time.sleep(5)\n",
    "\n",
    "#Scraping data of names of exceptions\n",
    "Name = []\n",
    "Description = []\n",
    "\n",
    "for i in driver.find_elements(By.XPATH ,'//div[@class=\"entry-content-wrap\"]/div/p')[:41]:\n",
    "    \n",
    "    k = i.text.split(':')\n",
    "    Name.append(k[0][2:].strip('.'))\n",
    "\n",
    "\n",
    "# #Scraping data of descriptions of exceptions  \n",
    "    Description.append(k[1])\n",
    "    \n",
    "#DATA FRAMEING\n",
    "Guru=pd.DataFrame({})\n",
    "Guru['Name of Exception'] = Name\n",
    "Guru['Description of Exception'] = Description\n",
    "\n",
    "#Printing data frame\n",
    "Guru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c8c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6efb8",
   "metadata": {},
   "source": [
    "### 4. Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/\n",
    "#### You have to find following details:\n",
    "#### A) Rank\n",
    "#### B) State\n",
    "#### C) GSDP(18-19)- at current prices\n",
    "#### D) GSDP(19-20)- at current prices\n",
    "#### E) Share(18-19)\n",
    "#### F) GDP($billion)\n",
    "### Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73aaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#getting the specified url\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf18573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on economy section\n",
    "economy = driver.find_element(By.XPATH ,\"//div[@class='navbar']//div[2]//button\").click()\n",
    "\n",
    "urls = driver.find_element(By.XPATH ,\"//div[@class='dropdown-content']//a[3]\")\n",
    "ineco_page = urls.get_attribute(\"href\")\n",
    "#Going to indian economy page\n",
    "driver.get(ineco_page)  \n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c29e0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP_1 = []\n",
    "GSDP_2 = []\n",
    "Share = []\n",
    "GDP = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57acbb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the url of page containing GDP of indian states\n",
    "sta_GDP = driver.find_element(By.XPATH ,\"//ul[@style='list-style-type:none;margin-left:20px;']/li/a\")\n",
    "GDP_url = sta_GDP.get_attribute(\"href\")\n",
    "\n",
    "driver.get(GDP_url)\n",
    "time.sleep(6)\n",
    "\n",
    "\n",
    "#Scraping data of rank\n",
    "for i in driver.find_elements(By.XPATH ,\"//div[@id='table_id_wrapper']//tbody//tr//td[1]\"):\n",
    "    Rank.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of state name\n",
    "for i in driver.find_elements(By.XPATH ,\"//div[@id='table_id_wrapper']//tbody//tr//td[2]\"):\n",
    "    State.append(i.text)\n",
    "\n",
    "    \n",
    "# Scraping data of GSDP at current price (19-20)\n",
    "for i in driver.find_elements(By.XPATH ,\"//div[@id='table_id_wrapper']//tbody//tr//td[3]\"):\n",
    "    GSDP_1.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of GSDP at current price (18-19)\n",
    "for i in driver.find_elements(By.XPATH ,\"//div[@id='table_id_wrapper']//tbody//tr//td[4]\"):\n",
    "    GSDP_2.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of Share(18-19)\n",
    "for i in driver.find_elements(By.XPATH ,\"//div[@id='table_id_wrapper']//tbody//tr//td[5]\"):\n",
    "    Share.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data of GDP($ billion)\n",
    "for i in driver.find_elements(By.XPATH ,\"//div[@id='table_id_wrapper']//tbody//tr//td[6]\"):\n",
    "    GDP.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e677c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price (19-20)</th>\n",
       "      <th>GSDP at current price (18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP at current price (19-20)  \\\n",
       "0     1                Maharashtra                             -   \n",
       "1     2                 Tamil Nadu                     1,845,853   \n",
       "2     3              Uttar Pradesh                     1,687,818   \n",
       "3     4                    Gujarat                             -   \n",
       "4     5                  Karnataka                     1,631,977   \n",
       "5     6                West Bengal                     1,253,832   \n",
       "6     7                  Rajasthan                     1,020,989   \n",
       "7     8             Andhra Pradesh                       972,782   \n",
       "8     9                  Telangana                       969,604   \n",
       "9    10             Madhya Pradesh                       906,672   \n",
       "10   11                     Kerala                             -   \n",
       "11   12                      Delhi                       856,112   \n",
       "12   13                    Haryana                       831,610   \n",
       "13   14                      Bihar                       611,804   \n",
       "14   15                     Punjab                       574,760   \n",
       "15   16                     Odisha                       521,275   \n",
       "16   17                      Assam                             -   \n",
       "17   18               Chhattisgarh                       329,180   \n",
       "18   19                  Jharkhand                       328,598   \n",
       "19   20                Uttarakhand                             -   \n",
       "20   21            Jammu & Kashmir                             -   \n",
       "21   22           Himachal Pradesh                       165,472   \n",
       "22   23                        Goa                        80,449   \n",
       "23   24                    Tripura                        55,984   \n",
       "24   25                 Chandigarh                             -   \n",
       "25   26                 Puducherry                        38,253   \n",
       "26   27                  Meghalaya                        36,572   \n",
       "27   28                     Sikkim                        32,496   \n",
       "28   29                    Manipur                        31,790   \n",
       "29   30                   Nagaland                             -   \n",
       "30   31          Arunachal Pradesh                             -   \n",
       "31   32                    Mizoram                        26,503   \n",
       "32   33  Andaman & Nicobar Islands                             -   \n",
       "\n",
       "   GSDP at current price (18-19) Share(18-19) GDP($ billion)  \n",
       "0                      2,632,792       13.94%        399.921  \n",
       "1                      1,630,208        8.63%        247.629  \n",
       "2                      1,584,764        8.39%        240.726  \n",
       "3                      1,502,899        7.96%        228.290  \n",
       "4                      1,493,127        7.91%        226.806  \n",
       "5                      1,089,898        5.77%        165.556  \n",
       "6                        942,586        4.99%        143.179  \n",
       "7                        862,957        4.57%        131.083  \n",
       "8                        861,031        4.56%        130.791  \n",
       "9                        809,592        4.29%        122.977  \n",
       "10                       781,653        4.14%        118.733  \n",
       "11                       774,870        4.10%        117.703  \n",
       "12                       734,163        3.89%        111.519  \n",
       "13                       530,363        2.81%         80.562  \n",
       "14                       526,376        2.79%         79.957  \n",
       "15                       487,805        2.58%         74.098  \n",
       "16                       315,881        1.67%         47.982  \n",
       "17                       304,063        1.61%         46.187  \n",
       "18                       297,204        1.57%         45.145  \n",
       "19                       245,895        1.30%         37.351  \n",
       "20                       155,956        0.83%         23.690  \n",
       "21                       153,845        0.81%         23.369  \n",
       "22                        73,170        0.39%         11.115  \n",
       "23                        49,845        0.26%          7.571  \n",
       "24                        42,114        0.22%          6.397  \n",
       "25                        34,433        0.18%          5.230  \n",
       "26                        33,481        0.18%          5.086  \n",
       "27                        28,723        0.15%          4.363  \n",
       "28                        27,870        0.15%          4.233  \n",
       "29                        27,283        0.14%          4.144  \n",
       "30                        24,603        0.13%          3.737  \n",
       "31                        22,287        0.12%          3.385  \n",
       "32                             -            -              -  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA FRAMEING\n",
    "StatisticsTime=pd.DataFrame({})\n",
    "StatisticsTime['Rank'] = Rank\n",
    "StatisticsTime['State'] = State\n",
    "StatisticsTime['GSDP at current price (19-20)'] = GSDP_1\n",
    "StatisticsTime['GSDP at current price (18-19)'] = GSDP_2\n",
    "StatisticsTime['Share(18-19)'] = Share\n",
    "StatisticsTime['GDP($ billion)'] = GDP\n",
    "\n",
    "#Printing the data frame\n",
    "StatisticsTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55704304",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93e9b0",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of trending repositories on Github.com. Url = https://github.com/\n",
    "#### You have to find the following details:\n",
    "##### A) Repository title\n",
    "##### B) Repository description\n",
    "##### C) Contributors count\n",
    "##### D) Language used\n",
    "###### Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3906dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver=driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver.exe\")\n",
    "\n",
    "# getting the webpage of mentioned url\n",
    "url = (\"https://github.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "557559c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting explore button and clicking on it\n",
    "explore = driver.find_element(By.XPATH ,'//nav[@class=\"mt-0 px-3 px-lg-0 mb-3 mb-lg-0\"]/ul/li[3]').click()\n",
    "#Selecting trending option\n",
    "trend_url = driver.find_element(By.XPATH ,'//nav[@class=\"mt-0 px-3 px-lg-0 mb-3 mb-lg-0\"]/ul/li[3]/div/ul[3]/li[3]/a')\n",
    "urls = trend_url.get_attribute(\"href\")\n",
    "driver.get(urls)\n",
    "\n",
    "#Creating empty list\n",
    "repo_urls = []\n",
    "rep_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []\n",
    "\n",
    "#Fetching urls for each repository\n",
    "repository = driver.find_elements(By.XPATH ,\"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "for i in repository:\n",
    "    repo_urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "    \n",
    "#Scraping data of repository title\n",
    "title = driver.find_elements(By.XPATH ,\"//h1[@class = 'h3 lh-condensed']\")\n",
    "for i in title:\n",
    "    rep_title.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping data from every repository page\n",
    "for i in repo_urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    #Scraping data of decription\n",
    "    try:\n",
    "        desc = driver.find_element(By.XPATH ,'//article[@class=\"markdown-body entry-content container-lg\"]/p[2]')\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "        \n",
    "        \n",
    "    #Scraping data of contributors\n",
    "    try:\n",
    "        cont_tags = driver.find_element(By.XPATH ,\"//*[contains(text(),'    Contributors ')]\")\n",
    "        Contributors.append(cont_tags.text.replace('Contributors',''))\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "        \n",
    "        \n",
    "    #fetching Languages used\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH ,'//div[@class=\"Layout-sidebar\"]/div/div[6]/div/ul/li/a/span[1]'):\n",
    "            lang.append(i.text)\n",
    "        Language.append(lang)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        Language.append('-')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fbdb5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fuergaosi233 / wechat-chatgpt</td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ggerganov / whisper.cpp</td>\n",
       "      <td>High-performance inference of OpenAI's Whisper...</td>\n",
       "      <td>25</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remix-run / react-router</td>\n",
       "      <td>If you're new to React Router, we recommend yo...</td>\n",
       "      <td>824</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AutumnWhj / ChatGPT-wechat-bot</td>\n",
       "      <td>Please check the root directory of your projec...</td>\n",
       "      <td>-</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paradigmxyz / reth</td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>869413421 / wechatbot</td>\n",
       "      <td>你可以使用docker快速运行本项目。</td>\n",
       "      <td>3</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rawandahmad698 / PyChatGPT</td>\n",
       "      <td>⭐️ Like this repo? please star &amp; consider dona...</td>\n",
       "      <td>7</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>surrealdb / surrealdb</td>\n",
       "      <td></td>\n",
       "      <td>31</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gragland / chatgpt-chrome-extension</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tencent / Hippy</td>\n",
       "      <td>Homepage</td>\n",
       "      <td>80</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>acheong08 / ChatGPT</td>\n",
       "      <td>Reverse Engineered ChatGPT by OpenAI. Extensib...</td>\n",
       "      <td>22</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>izackwu / TeachYourselfCS-CN</td>\n",
       "      <td>TeachYourselfCS 的中文翻译。</td>\n",
       "      <td>8</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rmcelreath / stat_rethinking_2023</td>\n",
       "      <td>Instructor: Richard McElreath</td>\n",
       "      <td>-</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ryanmcdermott / clean-code-javascript</td>\n",
       "      <td>Software engineering principles, from Robert C...</td>\n",
       "      <td>111</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>humanloop / awesome-chatgpt</td>\n",
       "      <td>This list started as personal collection of in...</td>\n",
       "      <td>5</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>louislam / uptime-kuma</td>\n",
       "      <td>It is a self-hosted monitoring tool like \"Upti...</td>\n",
       "      <td>209</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lydiahallie / javascript-questions</td>\n",
       "      <td>-</td>\n",
       "      <td>185</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>f / awesome-chatgpt-prompts</td>\n",
       "      <td>Add New Prompt</td>\n",
       "      <td>9</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LyraSearch / lyra</td>\n",
       "      <td></td>\n",
       "      <td>29</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vincelwt / chatgpt-mac</td>\n",
       "      <td>You can use Cmd+Shift+G (Mac) or Ctrl+Shift+G ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>openai / whisper</td>\n",
       "      <td>Whisper is a general-purpose speech recognitio...</td>\n",
       "      <td>31</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trekhleb / javascript-algorithms</td>\n",
       "      <td>This repository contains JavaScript based exam...</td>\n",
       "      <td>197</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>OpenBB-finance / OpenBBTerminal</td>\n",
       "      <td></td>\n",
       "      <td>152</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EbookFoundation / free-programming-books</td>\n",
       "      <td>This page is available as an easy-to-read webs...</td>\n",
       "      <td>2,480</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>donnemartin / system-design-primer</td>\n",
       "      <td>Help translate this guide!</td>\n",
       "      <td>116</td>\n",
       "      <td>[TypeScript, JavaScript, C++, Java, Objective-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Repository title  \\\n",
       "0              fuergaosi233 / wechat-chatgpt   \n",
       "1                    ggerganov / whisper.cpp   \n",
       "2                   remix-run / react-router   \n",
       "3             AutumnWhj / ChatGPT-wechat-bot   \n",
       "4                         paradigmxyz / reth   \n",
       "5                      869413421 / wechatbot   \n",
       "6                 rawandahmad698 / PyChatGPT   \n",
       "7                      surrealdb / surrealdb   \n",
       "8        gragland / chatgpt-chrome-extension   \n",
       "9                            Tencent / Hippy   \n",
       "10                       acheong08 / ChatGPT   \n",
       "11              izackwu / TeachYourselfCS-CN   \n",
       "12         rmcelreath / stat_rethinking_2023   \n",
       "13     ryanmcdermott / clean-code-javascript   \n",
       "14               humanloop / awesome-chatgpt   \n",
       "15                    louislam / uptime-kuma   \n",
       "16        lydiahallie / javascript-questions   \n",
       "17               f / awesome-chatgpt-prompts   \n",
       "18                         LyraSearch / lyra   \n",
       "19                    vincelwt / chatgpt-mac   \n",
       "20                          openai / whisper   \n",
       "21          trekhleb / javascript-algorithms   \n",
       "22           OpenBB-finance / OpenBBTerminal   \n",
       "23  EbookFoundation / free-programming-books   \n",
       "24        donnemartin / system-design-primer   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0                                                                     18   \n",
       "1   High-performance inference of OpenAI's Whisper...                 25   \n",
       "2   If you're new to React Router, we recommend yo...                824   \n",
       "3   Please check the root directory of your projec...                  -   \n",
       "4                                                                     12   \n",
       "5                                 你可以使用docker快速运行本项目。                  3   \n",
       "6   ⭐️ Like this repo? please star & consider dona...                  7   \n",
       "7                                                                     31   \n",
       "8                                                                      -   \n",
       "9                                            Homepage                 80   \n",
       "10  Reverse Engineered ChatGPT by OpenAI. Extensib...                 22   \n",
       "11                             TeachYourselfCS 的中文翻译。                  8   \n",
       "12                      Instructor: Richard McElreath                  -   \n",
       "13  Software engineering principles, from Robert C...                111   \n",
       "14  This list started as personal collection of in...                  5   \n",
       "15  It is a self-hosted monitoring tool like \"Upti...                209   \n",
       "16                                                  -                185   \n",
       "17                                     Add New Prompt                  9   \n",
       "18                                                                    29   \n",
       "19  You can use Cmd+Shift+G (Mac) or Ctrl+Shift+G ...                  3   \n",
       "20  Whisper is a general-purpose speech recognitio...                 31   \n",
       "21  This repository contains JavaScript based exam...                197   \n",
       "22                                                                   152   \n",
       "23  This page is available as an easy-to-read webs...              2,480   \n",
       "24                         Help translate this guide!                116   \n",
       "\n",
       "                                        Language used  \n",
       "0   [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "1   [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "2   [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "3   [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "4   [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "5   [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "6   [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "7   [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "8   [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "9   [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "10  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "11  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "12  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "13  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "14  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "15  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "16  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "17  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "18  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "19  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "20  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "21  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "22  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "23  [TypeScript, JavaScript, C++, Java, Objective-...  \n",
       "24  [TypeScript, JavaScript, C++, Java, Objective-...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA FRAMEING\n",
    "Github=pd.DataFrame({})\n",
    "Github['Repository title'] = rep_title\n",
    "Github['Repository description'] = Description\n",
    "Github['Contributors count'] = Contributors\n",
    "Github['Language used'] = Language\n",
    "\n",
    "#Printing data frame\n",
    "Github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "460afe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd2945",
   "metadata": {},
   "source": [
    "## Q6: Scrape the details of top 100 songs on billboard.com.\n",
    "#### Url = https://www.billboard.com/ You have to find the following details:\n",
    "#### A) Song name \n",
    "#### B) Artist name \n",
    "#### C) Last week rank\n",
    "#### D) Peak rank \n",
    "#### E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e203b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# getting the webpage of mentioned url\n",
    "url = (\"https://www.billboard.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d5694ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"//div[@class='u-overflow-hidden lrv-u-background-color-grey-lightest lrv-u-padding-t-150 u-padding-t-00@mobile-max u-padding-b-425@desktop-xl u-padding-b-325@tablet u-padding-b-250']\").click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1599e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div[1]/div[2]/span/a\").click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dbf4c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_name = []\n",
    "Artist_name = []\n",
    "Last_week = []\n",
    "Peak_rank = []\n",
    "Weeks_on = []\n",
    "\n",
    "so_name = driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/h3')\n",
    "for name in so_name:\n",
    "    Song_name.append(name.text)\n",
    "    \n",
    "#scraping the data of Artist_name\n",
    "try:\n",
    "    op_art = driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/span')\n",
    "    for os in op_art:\n",
    "        Artist_name.append(os.text)\n",
    "except NoSuchElementException:\n",
    "    Artist_name.append('-')\n",
    "\n",
    "\n",
    "#scraping data of display of the Last_week\n",
    "try:\n",
    "    last = driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]/span')\n",
    "    for disp in last:\n",
    "        Last_week.append(disp.text)\n",
    "except NoSuchElementException:\n",
    "    Last_week.append(\"-\")\n",
    "\n",
    "\n",
    "# scraping data of Peak_rank\n",
    "try:\n",
    "    rank = driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-bold-l u-font-size-32@tablet u-letter-spacing-0080@tablet\"]')\n",
    "    for pro in rank:\n",
    "        Peak_rank.append(pro.text)\n",
    "except NoSuchElementException:\n",
    "    Peak_rank.append('-')\n",
    "\n",
    "# scraping data of Weeks_on\n",
    "try:\n",
    "    week = driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]/span')\n",
    "    for pro in week:\n",
    "        Weeks_on.append(pro.text)\n",
    "except NoSuchElementException:\n",
    "    Weeks_on.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "47a89a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 200, 100, 200)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Song_name),len(Artist_name),len(Last_week),len(Peak_rank),len(Weeks_on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4bb7afe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Artist_name=Artist_name[0:100]\n",
    "len(Artist_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bc392cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Last_week=Last_week[0:100]\n",
    "len(Last_week)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f21019bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weeks_on=Weeks_on[0:100]\n",
    "len(Weeks_on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "45f7bcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rockin' Around The Christmas Tree</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Someday At Christmas</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>96</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vigilante Shit</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Forget Me</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Going, Going, Gone</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>99</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Miss You</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 song         Artist Last Peak Week\n",
       "0                           Anti-Hero   Taylor Swift    1    1    1\n",
       "1     All I Want For Christmas Is You              1    6    2    6\n",
       "2   Rockin' Around The Christmas Tree              1    5    3    5\n",
       "3                              Unholy              6   54    4   54\n",
       "4                    Jingle Bell Rock   Mariah Carey    6    5    6\n",
       "..                                ...            ...  ...  ...  ...\n",
       "95               Someday At Christmas             14   33   96   33\n",
       "96                     Vigilante Shit  Morgan Wallen    -   97    -\n",
       "97                          Forget Me             13    3   98    3\n",
       "98                 Going, Going, Gone              5   38   99   38\n",
       "99                           Miss You             29   27  100   27\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "top_song = pd.DataFrame()\n",
    "top_song['song'] = Song_name\n",
    "top_song['Artist'] = Artist_name\n",
    "top_song['Last'] = Last_week\n",
    "top_song['Peak'] = Peak_rank\n",
    "top_song['Week'] = Weeks_on\n",
    "top_song \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5f2d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a8323",
   "metadata": {},
   "source": [
    "### 7. Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/\n",
    "#### You have to find the following details:\n",
    "#### A) Name\n",
    "#### B) Designation\n",
    "#### C) Company\n",
    "#### D) Skills they hire for\n",
    "#### E) Location\n",
    "#### Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d0e9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver.exe\")\n",
    "\n",
    "# getting the webpage of mentioned url\n",
    "url = (\"https://www.naukri.com/\")\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbc9bb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n",
    "search_field = driver.find_element(By.CLASS_NAME,'suggestor-input ')\n",
    "search_field.send_keys('Data Science')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1d68e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6858c711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = []\n",
    "name_tag = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in name_tag:\n",
    "    name.append(i.text)\n",
    "len(name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce7cb7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = []\n",
    "comp_tag = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in comp_tag:\n",
    "    comp.append(i.text)\n",
    "len(comp)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df10871d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill = []\n",
    "skill_tag = driver.find_elements(By.XPATH,'//div[@class=\"job-description fs12 grey-text\"]')\n",
    "for i in skill_tag:\n",
    "    skill.append(i.text)\n",
    "len(skill)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebe12c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = []\n",
    "loc_tag = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 locWdth\"]')\n",
    "for i in loc_tag:\n",
    "    loc.append(i.text)\n",
    "len(loc)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b6cdc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>BS / MS or PhD in a quantitative field - Appli...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Data Science</td>\n",
       "      <td>Bristlecone</td>\n",
       "      <td>Graduation Post Graduation in Statistics Compe...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr. Manager - Data Science</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>Masters / PhDs in a quantitative field (Comput...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist - Data Sciences</td>\n",
       "      <td>GEP</td>\n",
       "      <td>, code review and version control tools, batch...</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>- We are looking for passionate and skilled da...</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst / Data Science</td>\n",
       "      <td>Infoweb</td>\n",
       "      <td>We are looking to hire a data analyst to join ...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>You will be required to utilize the existing f...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Skill required: Data Science - Python Programm...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Lead - Forecasting</td>\n",
       "      <td>Cargill</td>\n",
       "      <td>Bachelor s degree in Computer science, Statist...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>The ideal candidate should have a strong clien...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Paytm - Data Science - Lead</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>Bachelor s degree in technical/ analytics/ dat...</td>\n",
       "      <td>Noida, Mumbai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Consultant - Data Science</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Qualitative skills: Should have played project...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "      <td>Bizongo</td>\n",
       "      <td>5+ years of experience in designing, developin...</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Requirements: Responsible for taking up day-to...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Science- Data Scientist/Sr. Data Scientist</td>\n",
       "      <td>Jet2 Travel Technologies</td>\n",
       "      <td>As a part of J2TT, the successful candidate wi...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Deputy National Lead - Payments - Data Science</td>\n",
       "      <td>BAJAJ FINSERVE</td>\n",
       "      <td>Bachelor s Degree in computer science, Math, P...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Geeky Bee AI Pvt Ltd</td>\n",
       "      <td>We are looking for Data Science Engineers with...</td>\n",
       "      <td>Pune(Wakad)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Ira Commerce</td>\n",
       "      <td>Experience in Developing and enhancing algorit...</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Manager / Senior Manager - Data Science</td>\n",
       "      <td>PYLON Management Consulting Private Limited</td>\n",
       "      <td>Nice to have: Phd or degree from IIT / IIM/oth...</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Consultant/Senior Manager - Analytics/Data Sci...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>Analytics Consultant/ Senior Manager- Data Sci...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            JOB Title  \\\n",
       "0                                Analyst-Data Science   \n",
       "1                       Data Scientist - Data Science   \n",
       "2                          Sr. Manager - Data Science   \n",
       "3                 Lead Data Scientist - Data Sciences   \n",
       "4                  Data Science - Engineering Manager   \n",
       "5                         Data Analyst / Data Science   \n",
       "6                                Analyst-Data Science   \n",
       "7                         Senior Analyst-Data Science   \n",
       "8                     Data Science Lead - Forecasting   \n",
       "9   ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "10                        Paytm - Data Science - Lead   \n",
       "11                          Consultant - Data Science   \n",
       "12                       Senior Data Science Engineer   \n",
       "13  ACN - Applied Intelligence - CC - Data Science...   \n",
       "14    Data Science- Data Scientist/Sr. Data Scientist   \n",
       "15     Deputy National Lead - Payments - Data Science   \n",
       "16                              Data Science Engineer   \n",
       "17                               Data Science Analyst   \n",
       "18            Manager / Senior Manager - Data Science   \n",
       "19  Consultant/Senior Manager - Analytics/Data Sci...   \n",
       "\n",
       "                                        Company  \\\n",
       "0                              AMERICAN EXPRESS   \n",
       "1                                   Bristlecone   \n",
       "2                              AMERICAN EXPRESS   \n",
       "3                                           GEP   \n",
       "4                                         Paytm   \n",
       "5                                       Infoweb   \n",
       "6                                     Accenture   \n",
       "7                                     Accenture   \n",
       "8                                       Cargill   \n",
       "9                                     Accenture   \n",
       "10                                        Paytm   \n",
       "11                             Affine Analytics   \n",
       "12                                      Bizongo   \n",
       "13                                    Accenture   \n",
       "14                     Jet2 Travel Technologies   \n",
       "15                               BAJAJ FINSERVE   \n",
       "16                         Geeky Bee AI Pvt Ltd   \n",
       "17                                 Ira Commerce   \n",
       "18  PYLON Management Consulting Private Limited   \n",
       "19                    Huquo Consulting Pvt. Ltd   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   BS / MS or PhD in a quantitative field - Appli...   \n",
       "1   Graduation Post Graduation in Statistics Compe...   \n",
       "2   Masters / PhDs in a quantitative field (Comput...   \n",
       "3   , code review and version control tools, batch...   \n",
       "4   - We are looking for passionate and skilled da...   \n",
       "5   We are looking to hire a data analyst to join ...   \n",
       "6   You will be required to utilize the existing f...   \n",
       "7   Skill required: Data Science - Python Programm...   \n",
       "8   Bachelor s degree in Computer science, Statist...   \n",
       "9   The ideal candidate should have a strong clien...   \n",
       "10  Bachelor s degree in technical/ analytics/ dat...   \n",
       "11  Qualitative skills: Should have played project...   \n",
       "12  5+ years of experience in designing, developin...   \n",
       "13  Requirements: Responsible for taking up day-to...   \n",
       "14  As a part of J2TT, the successful candidate wi...   \n",
       "15  Bachelor s Degree in computer science, Math, P...   \n",
       "16  We are looking for Data Science Engineers with...   \n",
       "17  Experience in Developing and enhancing algorit...   \n",
       "18  Nice to have: Phd or degree from IIT / IIM/oth...   \n",
       "19  Analytics Consultant/ Senior Manager- Data Sci...   \n",
       "\n",
       "                                       Location  \n",
       "0                              Gurgaon/Gurugram  \n",
       "1                                        Mumbai  \n",
       "2                              Gurgaon/Gurugram  \n",
       "3                                        Remote  \n",
       "4                New Delhi, Bangalore/Bengaluru  \n",
       "5                                          Pune  \n",
       "6                           Bangalore/Bengaluru  \n",
       "7                                        Mumbai  \n",
       "8                           Bangalore/Bengaluru  \n",
       "9                           Bangalore/Bengaluru  \n",
       "10           Noida, Mumbai, Bangalore/Bengaluru  \n",
       "11                          Bangalore/Bengaluru  \n",
       "12                  Mumbai, Bangalore/Bengaluru  \n",
       "13                             Gurgaon/Gurugram  \n",
       "14                                         Pune  \n",
       "15                                         Pune  \n",
       "16                                  Pune(Wakad)  \n",
       "17                       Hyderabad/Secunderabad  \n",
       "18  Pune, Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "19        Gurgaon/Gurugram, Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'JOB Title':name,'Company':comp,'Skills':skill,'Location':loc})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49831e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad71ce5e",
   "metadata": {},
   "source": [
    "### 8. Scrape the details of Highest selling novels.\n",
    "#### Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey- compare/\n",
    "#### You have to find the following details:\n",
    "#### A) Book name\n",
    "#### B) Author name\n",
    "#### C) Volumes sold\n",
    "#### D) Publisher\n",
    "#### E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51d20e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver.exe\")\n",
    "\n",
    "# getting the webpage of mentioned url\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')\n",
    "driver.maximize_window()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67e43bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'Da Vinci Code,The',\n",
       " 'Brown, Dan',\n",
       " '5,094,805',\n",
       " 'Transworld',\n",
       " '2',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " 'Rowling, J.K.',\n",
       " '4,475,152',\n",
       " 'Bloomsbury',\n",
       " '3',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Rowling, J.K.',\n",
       " '4,200,654',\n",
       " 'Bloomsbury',\n",
       " '4',\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Rowling, J.K.',\n",
       " '4,179,479',\n",
       " 'Bloomsbury',\n",
       " '5',\n",
       " 'Fifty Shades of Grey',\n",
       " 'James, E. L.',\n",
       " '3,758,936',\n",
       " 'Random House',\n",
       " '6',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Rowling, J.K.',\n",
       " '3,583,215',\n",
       " 'Bloomsbury',\n",
       " '7',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Rowling, J.K.',\n",
       " '3,484,047',\n",
       " 'Bloomsbury',\n",
       " '8',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Rowling, J.K.',\n",
       " '3,377,906',\n",
       " 'Bloomsbury',\n",
       " '9',\n",
       " 'Angels and Demons',\n",
       " 'Brown, Dan',\n",
       " '3,193,946',\n",
       " 'Transworld',\n",
       " '10',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Rowling, J.K.',\n",
       " '2,950,264',\n",
       " 'Bloomsbury',\n",
       " '11',\n",
       " 'Fifty Shades Darker',\n",
       " 'James, E. L.',\n",
       " '2,479,784',\n",
       " 'Random House',\n",
       " '12',\n",
       " 'Twilight',\n",
       " 'Meyer, Stephenie',\n",
       " '2,315,405',\n",
       " 'Little, Brown Book',\n",
       " '13',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Larsson, Stieg',\n",
       " '2,233,570',\n",
       " 'Quercus',\n",
       " '14',\n",
       " 'Fifty Shades Freed',\n",
       " 'James, E. L.',\n",
       " '2,193,928',\n",
       " 'Random House',\n",
       " '15',\n",
       " 'Lost Symbol,The',\n",
       " 'Brown, Dan',\n",
       " '2,183,031',\n",
       " 'Transworld',\n",
       " '16',\n",
       " 'New Moon',\n",
       " 'Meyer, Stephenie',\n",
       " '2,152,737',\n",
       " 'Little, Brown Book',\n",
       " '17',\n",
       " 'Deception Point',\n",
       " 'Brown, Dan',\n",
       " '2,062,145',\n",
       " 'Transworld',\n",
       " '18',\n",
       " 'Eclipse',\n",
       " 'Meyer, Stephenie',\n",
       " '2,052,876',\n",
       " 'Little, Brown Book',\n",
       " '19',\n",
       " 'Lovely Bones,The',\n",
       " 'Sebold, Alice',\n",
       " '2,005,598',\n",
       " 'Pan Macmillan',\n",
       " '20',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Haddon, Mark',\n",
       " '1,979,552',\n",
       " 'Random House',\n",
       " '21',\n",
       " 'Digital Fortress',\n",
       " 'Brown, Dan',\n",
       " '1,928,900',\n",
       " 'Transworld',\n",
       " '22',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Bryson, Bill',\n",
       " '1,852,919',\n",
       " 'Transworld',\n",
       " '23',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Larsson, Stieg',\n",
       " '1,814,784',\n",
       " 'Quercus',\n",
       " '24',\n",
       " 'Breaking Dawn',\n",
       " 'Meyer, Stephenie',\n",
       " '1,787,118',\n",
       " 'Little, Brown Book',\n",
       " '25',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Carle, Eric',\n",
       " '1,783,535',\n",
       " 'Penguin',\n",
       " '26',\n",
       " 'Gruffalo,The',\n",
       " 'Donaldson, Julia',\n",
       " '1,781,269',\n",
       " 'Pan Macmillan',\n",
       " '27',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Oliver, Jamie',\n",
       " '1,743,266',\n",
       " 'Penguin',\n",
       " '28',\n",
       " 'Kite Runner,The',\n",
       " 'Hosseini, Khaled',\n",
       " '1,629,119',\n",
       " 'Bloomsbury',\n",
       " '29',\n",
       " 'One Day',\n",
       " 'Nicholls, David',\n",
       " '1,616,068',\n",
       " 'Hodder & Stoughton',\n",
       " '30',\n",
       " 'Thousand Splendid Suns,A',\n",
       " 'Hosseini, Khaled',\n",
       " '1,583,992',\n",
       " 'Bloomsbury',\n",
       " '31',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " 'Larsson, Stieg',\n",
       " '1,555,135',\n",
       " 'Quercus',\n",
       " '32',\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Niffenegger, Audrey',\n",
       " '1,546,886',\n",
       " 'Random House',\n",
       " '33',\n",
       " 'Atonement',\n",
       " 'McEwan, Ian',\n",
       " '1,539,428',\n",
       " 'Random House',\n",
       " '34',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'Fielding, Helen',\n",
       " '1,508,205',\n",
       " 'Pan Macmillan',\n",
       " '35',\n",
       " 'World According to Clarkson,The',\n",
       " 'Clarkson, Jeremy',\n",
       " '1,489,403',\n",
       " 'Penguin',\n",
       " '36',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Bernieres, Louis de',\n",
       " '1,352,318',\n",
       " 'Random House',\n",
       " '37',\n",
       " 'Sound of Laughter,The',\n",
       " 'Kay, Peter',\n",
       " '1,310,207',\n",
       " 'Random House',\n",
       " '38',\n",
       " 'Life of Pi',\n",
       " 'Martel, Yann',\n",
       " '1,310,176',\n",
       " 'Canongate',\n",
       " '39',\n",
       " 'Billy Connolly',\n",
       " 'Stephenson, Pamela',\n",
       " '1,231,957',\n",
       " 'HarperCollins',\n",
       " '40',\n",
       " 'Child Called It,A',\n",
       " 'Pelzer, Dave',\n",
       " '1,217,712',\n",
       " 'Orion',\n",
       " '41',\n",
       " \"Gruffalo's Child,The\",\n",
       " 'Donaldson, Julia',\n",
       " '1,208,711',\n",
       " 'Pan Macmillan',\n",
       " '42',\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'McCourt, Frank',\n",
       " '1,204,058',\n",
       " 'HarperCollins',\n",
       " '43',\n",
       " 'Birdsong',\n",
       " 'Faulks, Sebastian',\n",
       " '1,184,967',\n",
       " 'Random House',\n",
       " '44',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,181,503',\n",
       " 'Scholastic Ltd.',\n",
       " '45',\n",
       " 'Labyrinth',\n",
       " 'Mosse, Kate',\n",
       " '1,181,093',\n",
       " 'Orion',\n",
       " '46',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Rowling, J.K.',\n",
       " '1,153,181',\n",
       " 'Bloomsbury',\n",
       " '47',\n",
       " 'Help,The',\n",
       " 'Stockett, Kathryn',\n",
       " '1,132,336',\n",
       " 'Penguin',\n",
       " '48',\n",
       " 'Man and Boy',\n",
       " 'Parsons, Tony',\n",
       " '1,130,802',\n",
       " 'HarperCollins',\n",
       " '49',\n",
       " 'Memoirs of a Geisha',\n",
       " 'Golden, Arthur',\n",
       " '1,126,337',\n",
       " 'Random House',\n",
       " '50',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'McCall Smith, Alexander',\n",
       " '1,115,549',\n",
       " 'Little, Brown Book',\n",
       " '51',\n",
       " 'Island,The',\n",
       " 'Hislop, Victoria',\n",
       " '1,108,328',\n",
       " 'Headline',\n",
       " '52',\n",
       " 'PS, I Love You',\n",
       " 'Ahern, Cecelia',\n",
       " '1,107,379',\n",
       " 'HarperCollins',\n",
       " '53',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'McKeith, Gillian',\n",
       " '1,104,403',\n",
       " 'Penguin',\n",
       " '54',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " '1,092,349',\n",
       " 'Orion',\n",
       " '55',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Rowling, J.K.',\n",
       " '1,090,847',\n",
       " 'Bloomsbury',\n",
       " '56',\n",
       " 'Broker,The',\n",
       " 'Grisham, John',\n",
       " '1,087,262',\n",
       " 'Random House',\n",
       " '57',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Atkins, Robert C.',\n",
       " '1,054,196',\n",
       " 'Random House',\n",
       " '58',\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,037,160',\n",
       " 'Scholastic Ltd.',\n",
       " '59',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " 'Truss, Lynne',\n",
       " '1,023,688',\n",
       " 'Profile Books Group',\n",
       " '60',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Smith, Delia',\n",
       " '1,015,956',\n",
       " 'Random House',\n",
       " '61',\n",
       " 'Chocolat',\n",
       " 'Harris, Joanne',\n",
       " '1,009,873',\n",
       " 'Transworld',\n",
       " '62',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " 'Boyne, John',\n",
       " '1,004,414',\n",
       " 'Random House Childrens Books G',\n",
       " '63',\n",
       " \"My Sister's Keeper\",\n",
       " 'Picoult, Jodi',\n",
       " '1,003,780',\n",
       " 'Hodder & Stoughton',\n",
       " '64',\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,002,314',\n",
       " 'Scholastic Ltd.',\n",
       " '65',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Lee, Harper',\n",
       " '998,213',\n",
       " 'Random House',\n",
       " '66',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Gray, John',\n",
       " '992,846',\n",
       " 'HarperCollins',\n",
       " '67',\n",
       " 'Dear Fatty',\n",
       " 'French, Dawn',\n",
       " '986,753',\n",
       " 'Random House',\n",
       " '68',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Lewycka, Marina',\n",
       " '986,115',\n",
       " 'Penguin',\n",
       " '69',\n",
       " 'Hannibal',\n",
       " 'Harris, Thomas',\n",
       " '970,509',\n",
       " 'Random House',\n",
       " '70',\n",
       " 'Lord of the Rings,The',\n",
       " 'Tolkien, J. R. R.',\n",
       " '967,466',\n",
       " 'HarperCollins',\n",
       " '71',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Moore, Michael',\n",
       " '963,353',\n",
       " 'Penguin',\n",
       " '72',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Rubenfeld, Jed',\n",
       " '962,515',\n",
       " 'Headline',\n",
       " '73',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Osbourne, Sharon',\n",
       " '959,496',\n",
       " 'Little, Brown Book',\n",
       " '74',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " 'Coelho, Paulo',\n",
       " '956,114',\n",
       " 'HarperCollins',\n",
       " '75',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " \"O'Grady, Paul\",\n",
       " '945,640',\n",
       " 'Transworld',\n",
       " '76',\n",
       " 'Notes from a Small Island',\n",
       " 'Bryson, Bill',\n",
       " '931,312',\n",
       " 'Transworld',\n",
       " '77',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Oliver, Jamie',\n",
       " '925,425',\n",
       " 'Penguin',\n",
       " '78',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " 'Fielding, Helen',\n",
       " '924,695',\n",
       " 'Pan Macmillan',\n",
       " '79',\n",
       " \"Jamie's Italy\",\n",
       " 'Oliver, Jamie',\n",
       " '906,968',\n",
       " 'Penguin',\n",
       " '80',\n",
       " 'I Can Make You Thin',\n",
       " 'McKenna, Paul',\n",
       " '905,086',\n",
       " 'Transworld',\n",
       " '81',\n",
       " 'Down Under',\n",
       " 'Bryson, Bill',\n",
       " '890,847',\n",
       " 'Transworld',\n",
       " '82',\n",
       " 'Summons,The',\n",
       " 'Grisham, John',\n",
       " '869,671',\n",
       " 'Random House',\n",
       " '83',\n",
       " 'Small Island',\n",
       " 'Levy, Andrea',\n",
       " '869,659',\n",
       " 'Headline',\n",
       " '84',\n",
       " 'Nigella Express',\n",
       " 'Lawson, Nigella',\n",
       " '862,602',\n",
       " 'Random House',\n",
       " '85',\n",
       " 'Brick Lane',\n",
       " 'Ali, Monica',\n",
       " '856,540',\n",
       " 'Transworld',\n",
       " '86',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Edwards, Kim',\n",
       " '845,858',\n",
       " 'Penguin',\n",
       " '87',\n",
       " 'Room on the Broom',\n",
       " 'Donaldson, Julia',\n",
       " '842,535',\n",
       " 'Pan Macmillan',\n",
       " '88',\n",
       " 'About a Boy',\n",
       " 'Hornby, Nick',\n",
       " '828,215',\n",
       " 'Penguin',\n",
       " '89',\n",
       " 'My Booky Wook',\n",
       " 'Brand, Russell',\n",
       " '820,563',\n",
       " 'Hodder & Stoughton',\n",
       " '90',\n",
       " 'God Delusion,The',\n",
       " 'Dawkins, Richard',\n",
       " '816,907',\n",
       " 'Transworld',\n",
       " '91',\n",
       " '\"Beano\" Annual,The',\n",
       " '0',\n",
       " '816,585',\n",
       " 'D.C. Thomson',\n",
       " '92',\n",
       " 'White Teeth',\n",
       " 'Smith, Zadie',\n",
       " '815,586',\n",
       " 'Penguin',\n",
       " '93',\n",
       " 'House at Riverton,The',\n",
       " 'Morton, Kate',\n",
       " '814,370',\n",
       " 'Pan Macmillan',\n",
       " '94',\n",
       " 'Book Thief,The',\n",
       " 'Zusak, Markus',\n",
       " '809,641',\n",
       " 'Transworld',\n",
       " '95',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Binchy, Maeve',\n",
       " '808,900',\n",
       " 'Orion',\n",
       " '96',\n",
       " 'Ghost,The',\n",
       " 'Harris, Robert',\n",
       " '807,311',\n",
       " 'Random House',\n",
       " '97',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Oliver, Jamie',\n",
       " '794,201',\n",
       " 'Penguin',\n",
       " '98',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " 'Collins, Suzanne',\n",
       " '792,187',\n",
       " 'Scholastic Ltd.',\n",
       " '99',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " 'Pelzer, Dave',\n",
       " '791,507',\n",
       " 'Orion',\n",
       " '100',\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\",\n",
       " 'Oliver, Jamie',\n",
       " '791,095',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = []\n",
    "detail_tag = driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "for i in detail_tag:\n",
    "    detail.append(i.text)\n",
    "detail    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8dec658",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = detail[0:500:5]\n",
    "book_name = detail[1:500:5]\n",
    "author_name=detail[2:500:5]\n",
    "vol_sales=detail[3:500:5]\n",
    "publisher = detail[4:500:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee26d9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = []\n",
    "genre_tag =driver.find_elements(By.XPATH,'//td[@class=\"last left\"]')\n",
    "for i in genre_tag:\n",
    "    genre.append(i.text)\n",
    "len(genre)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6be4bdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                          Book Name       Author Name  \\\n",
       "0     1                                  Da Vinci Code,The        Brown, Dan   \n",
       "1     2               Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2     3           Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3     4          Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4     5                               Fifty Shades of Grey      James, E. L.   \n",
       "..  ...                                                ...               ...   \n",
       "95   96                                          Ghost,The    Harris, Robert   \n",
       "96   97                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97   98              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98   99  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sales        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank':rank,'Book Name':book_name,'Author Name':author_name,'Volume Sales':vol_sales,'Publisher':publisher,'Genre':genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc9f194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b321c2",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "711a9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver.exe\")\n",
    "\n",
    "# getting the webpage of mentioned url\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "driver.maximize_window()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80c7a942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Stranger Things',\n",
       " 'The Walking Dead',\n",
       " '13 Reasons Why',\n",
       " 'The 100',\n",
       " 'Orange Is the New Black',\n",
       " 'Riverdale',\n",
       " \"Grey's Anatomy\",\n",
       " 'The Flash',\n",
       " 'Arrow',\n",
       " 'Money Heist',\n",
       " 'The Big Bang Theory',\n",
       " 'Black Mirror',\n",
       " 'Sherlock',\n",
       " 'Vikings',\n",
       " 'Pretty Little Liars',\n",
       " 'The Vampire Diaries',\n",
       " 'American Horror Story',\n",
       " 'Breaking Bad',\n",
       " 'Lucifer',\n",
       " 'Supernatural',\n",
       " 'Prison Break',\n",
       " 'How to Get Away with Murder',\n",
       " 'Teen Wolf',\n",
       " 'The Simpsons',\n",
       " 'Once Upon a Time',\n",
       " 'Narcos',\n",
       " 'Daredevil',\n",
       " 'Friends',\n",
       " 'How I Met Your Mother',\n",
       " 'Suits',\n",
       " 'Mr. Robot',\n",
       " 'The Originals',\n",
       " 'Supergirl',\n",
       " 'Gossip Girl',\n",
       " 'Sense8',\n",
       " 'Gotham',\n",
       " 'Westworld',\n",
       " 'Jessica Jones',\n",
       " 'Modern Family',\n",
       " 'Rick and Morty',\n",
       " 'Shadowhunters',\n",
       " 'The End of the F***ing World',\n",
       " 'House of Cards',\n",
       " 'Dark',\n",
       " 'Elite',\n",
       " 'Sex Education',\n",
       " 'Shameless',\n",
       " 'New Girl',\n",
       " 'Agents of S.H.I.E.L.D.',\n",
       " 'You',\n",
       " 'Dexter',\n",
       " 'Fear the Walking Dead',\n",
       " 'Family Guy',\n",
       " 'The Blacklist',\n",
       " 'Lost',\n",
       " 'Peaky Blinders',\n",
       " 'House',\n",
       " 'Quantico',\n",
       " 'Orphan Black',\n",
       " 'Homeland',\n",
       " 'Blindspot',\n",
       " \"DC's Legends of Tomorrow\",\n",
       " \"The Handmaid's Tale\",\n",
       " 'Chilling Adventures of Sabrina',\n",
       " 'The Good Doctor',\n",
       " 'Jane the Virgin',\n",
       " 'Glee',\n",
       " 'South Park',\n",
       " 'Brooklyn Nine-Nine',\n",
       " 'Under the Dome',\n",
       " 'The Umbrella Academy',\n",
       " 'True Detective',\n",
       " 'The OA',\n",
       " 'Desperate Housewives',\n",
       " 'Better Call Saul',\n",
       " 'Bates Motel',\n",
       " 'The Punisher',\n",
       " 'Atypical',\n",
       " 'Dynasty',\n",
       " 'This Is Us',\n",
       " 'The Good Place',\n",
       " 'Iron Fist',\n",
       " 'The Rain',\n",
       " 'Mindhunter',\n",
       " 'Revenge',\n",
       " 'Luke Cage',\n",
       " 'Scandal',\n",
       " 'The Defenders',\n",
       " 'Big Little Lies',\n",
       " 'Insatiable',\n",
       " 'The Mentalist',\n",
       " 'The Crown',\n",
       " 'Chernobyl',\n",
       " 'iZombie',\n",
       " 'Reign',\n",
       " 'A Series of Unfortunate Events',\n",
       " 'Criminal Minds',\n",
       " 'Scream: The TV Series',\n",
       " 'The Haunting of Hill House']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = []\n",
    "detail_tag = driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]//a')\n",
    "for i in detail_tag:\n",
    "    detail.append(i.text)\n",
    "detail    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa074b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016– )',\n",
       " '(2010–2022)',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017– )',\n",
       " '(2005– )',\n",
       " '(2014–2023)',\n",
       " '(2012–2020)',\n",
       " '(2017–2021)',\n",
       " '(2007–2019)',\n",
       " '(2011–2019)',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016–2021)',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015–2021)',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016–2022)',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018– )',\n",
       " '(2006–2013)',\n",
       " '(2015– )',\n",
       " '(1999– )',\n",
       " '(2013– )',\n",
       " '(2004–2010)',\n",
       " '(2013–2022)',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016–2022)',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2021)',\n",
       " '(2013–2015)',\n",
       " '(2019–2023)',\n",
       " '(2014–2019)',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015–2022)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017–2021)',\n",
       " '(2017–2022)',\n",
       " '(2016–2022)',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016–2018)',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008–2015)',\n",
       " '(2016– )',\n",
       " '(2019– )',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005– )',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = []\n",
    "year_tag = driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in year_tag:\n",
    "    year.append(i.text)\n",
    "year    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ebc9483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '8.7',\n",
       " '8.1',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '6.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.5',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '6.2',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '8.5',\n",
       " '9.1',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '7.3',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '6.8',\n",
       " '8.2',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.4',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '6.8',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.5',\n",
       " '7.9',\n",
       " '8.9',\n",
       " '7.8',\n",
       " '7.6',\n",
       " '8.9',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '6.4',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.2',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '9.4',\n",
       " '7.8',\n",
       " '7.4',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7.1',\n",
       " '8.6']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []\n",
    "rating_tag = driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]')\n",
    "for i in rating_tag:\n",
    "    rating.append(i.text.split('\\n')[0])\n",
    "rating    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01e13c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = []\n",
    "run_tag = driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in run_tag:\n",
    "    run.append(i.text)\n",
    "run    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d2ebe44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = []\n",
    "genre_tag = driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for i in genre_tag:\n",
    "    genre.append(i.text)\n",
    "genre  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b21f5beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,090,968',\n",
       " '1,180,461',\n",
       " '989,459',\n",
       " '292,961',\n",
       " '252,122',\n",
       " '303,012',\n",
       " '145,547',\n",
       " '309,050',\n",
       " '346,399',\n",
       " '432,048',\n",
       " '476,250',\n",
       " '807,445',\n",
       " '545,957',\n",
       " '924,620',\n",
       " '531,920',\n",
       " '168,076',\n",
       " '322,383',\n",
       " '319,791',\n",
       " '1,873,803',\n",
       " '324,585',\n",
       " '445,857',\n",
       " '535,507',\n",
       " '152,321',\n",
       " '149,003',\n",
       " '407,580',\n",
       " '225,505',\n",
       " '422,137',\n",
       " '440,956',\n",
       " '993,220',\n",
       " '683,349',\n",
       " '410,991',\n",
       " '387,840',\n",
       " '136,656',\n",
       " '124,450',\n",
       " '175,517',\n",
       " '155,038',\n",
       " '230,979',\n",
       " '505,131',\n",
       " '215,230',\n",
       " '430,812',\n",
       " '519,975',\n",
       " '64,136',\n",
       " '191,006',\n",
       " '504,738',\n",
       " '385,649',\n",
       " '79,738',\n",
       " '280,766',\n",
       " '243,482',\n",
       " '225,149',\n",
       " '217,694',\n",
       " '240,666',\n",
       " '725,563',\n",
       " '130,476',\n",
       " '340,098',\n",
       " '249,856',\n",
       " '553,621',\n",
       " '546,807',\n",
       " '465,042',\n",
       " '61,276',\n",
       " '111,559',\n",
       " '342,109',\n",
       " '74,418',\n",
       " '105,262',\n",
       " '237,275',\n",
       " '95,853',\n",
       " '95,601',\n",
       " '51,180',\n",
       " '149,023',\n",
       " '369,696',\n",
       " '316,332',\n",
       " '107,053',\n",
       " '248,382',\n",
       " '570,620',\n",
       " '105,489',\n",
       " '129,647',\n",
       " '525,867',\n",
       " '108,759',\n",
       " '236,662',\n",
       " '89,503',\n",
       " '22,890',\n",
       " '144,476',\n",
       " '160,799',\n",
       " '131,778',\n",
       " '37,615',\n",
       " '288,873',\n",
       " '120,505',\n",
       " '131,870',\n",
       " '74,359',\n",
       " '108,525',\n",
       " '199,680',\n",
       " '29,136',\n",
       " '185,791',\n",
       " '217,104',\n",
       " '749,036',\n",
       " '68,723',\n",
       " '50,204',\n",
       " '61,505',\n",
       " '198,478',\n",
       " '41,586',\n",
       " '245,381']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes = []\n",
    "votes_tag = driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "for i in votes_tag:\n",
    "    votes.append(i.text)\n",
    "votes  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8a3a319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,090,968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,180,461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>989,459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>292,961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>252,122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>198,478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>245,381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,090,968  \n",
       "1    51 min     8.7  1,180,461  \n",
       "2    44 min     8.1    989,459  \n",
       "3    60 min     7.5    292,961  \n",
       "4    43 min     7.6    252,122  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,204  \n",
       "96   50 min     7.8     61,505  \n",
       "97   42 min     8.1    198,478  \n",
       "98   45 min     7.1     41,586  \n",
       "99  572 min     8.6    245,381  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({'Name':detail,'Year span':year,'Genre':genre,'Run time':run,'Ratings':rating,'Votes':votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3135047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c5c4a",
   "metadata": {},
   "source": [
    "#### 10. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/\n",
    "#### You have to find the following details:\n",
    "#### A) Dataset name\n",
    "#### B) Data type\n",
    "#### C) Task\n",
    "#### D) Attribute type\n",
    "#### E) No of instances\n",
    "#### F) No of attribute\n",
    "#### G) Year\n",
    "#### Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c3d2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver.exe\")\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f3c392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/index.php\"\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f5ce418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_btn=driver.find_element(By.XPATH,\"/html/body/table[1]/tbody/tr/td[2]/span[2]\") \n",
    "dataset_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6f99b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attribute = []\n",
    "Year = []\n",
    "\n",
    "\n",
    "N_name = driver.find_elements(By.XPATH,'//p[@class=\"normal\"]//b//a')\n",
    "for name in N_name:\n",
    "    Dataset_name.append(name.text)\n",
    "    \n",
    "#scraping the data of data\n",
    "try:\n",
    "    op_data = driver.find_elements(By.XPATH,'//table[2]//tbody[1]//tr[1]//td[3]//p[@class=\"normal\"]')\n",
    "    for os in op_data:\n",
    "        Data_type.append(os.text)\n",
    "except NoSuchElementException:\n",
    "    Data_type.append('-')\n",
    "\n",
    "\n",
    "#scraping data of display of the Task\n",
    "try:\n",
    "    task = driver.find_elements(By.XPATH,'//table[2]//tbody[1]//tr[1]//td[4]//p[@class=\"normal\"]')\n",
    "    for disp in task:\n",
    "        Task.append(disp.text)\n",
    "except NoSuchElementException:\n",
    "    Task.append(\"-\")\n",
    "\n",
    "\n",
    "# scraping data of Attribute type\n",
    "try:\n",
    "    att = driver.find_elements(By.XPATH,'//table[2]//tbody[1]//tr[1]//td[4]//p[@class=\"normal\"]')\n",
    "    for pro in att:\n",
    "        Attribute_type.append(pro.text)\n",
    "except NoSuchElementException:\n",
    "     Attribute_type.append('-')\n",
    "\n",
    "\n",
    "# scraping the data of No_of_instances\n",
    "try:\n",
    "    inst = driver.find_elements(By.XPATH,'//table[2]//tbody[1]//tr[1]//td[5]//p[@class=\"normal\"]')\n",
    "    for memo in inst:\n",
    "        No_of_instances.append(memo.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_instances.append('-')\n",
    "    \n",
    "    \n",
    "# scraping the data of No_of_attribute\n",
    "try:\n",
    "    attri = driver.find_elements(By.XPATH,'//table[2]//tbody[1]//tr[1]//td[6]//p[@class=\"normal\"]')\n",
    "    for memo in attri:\n",
    "        No_of_attribute.append(memo.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_attribute.append('-')   \n",
    "    \n",
    "    \n",
    "# scraping the data of Year\n",
    "try:\n",
    "    year = driver.find_elements(By.XPATH,'//table[2]//tbody[1]//tr[1]//td[7]//p[@class=\"normal\"]')\n",
    "    for mem in year:\n",
    "        Year.append(mem.text)\n",
    "except NoSuchElementException:\n",
    "    Year.append('-')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "abb68336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name             Data type  \\\n",
       "0                                              Abalone       Classification    \n",
       "1                                                Adult       Classification    \n",
       "2                                            Annealing       Classification    \n",
       "3                         Anonymous Microsoft Web Data  Recommender-Systems    \n",
       "4                                           Arrhythmia       Classification    \n",
       "..                                                 ...                   ...   \n",
       "617  Influenza outbreak event prediction via Twitte...       Classification    \n",
       "618                      Turkish Music Emotion Dataset       Classification    \n",
       "619                      Maternal Health Risk Data Set       Classification    \n",
       "620                          Room Occupancy Estimation       Classification    \n",
       "621  Image Recognition Task Execution Times in Mobi...           Regression    \n",
       "\n",
       "                            Task               Attribute_type No_of_instances  \\\n",
       "0    Categorical, Integer, Real   Categorical, Integer, Real            4177    \n",
       "1          Categorical, Integer         Categorical, Integer           48842    \n",
       "2    Categorical, Integer, Real   Categorical, Integer, Real             798    \n",
       "3                   Categorical                  Categorical           37711    \n",
       "4    Categorical, Integer, Real   Categorical, Integer, Real             452    \n",
       "..                           ...                          ...             ...   \n",
       "617               Integer, Real                Integer, Real           75840    \n",
       "618               Integer, Real                Integer, Real             400    \n",
       "619                                                                     1014    \n",
       "620                        Real                         Real           10129    \n",
       "621                        Real                         Real            4000    \n",
       "\n",
       "    No_of_attribute   Year  \n",
       "0                8   1995   \n",
       "1               14   1996   \n",
       "2               38          \n",
       "3              294   1998   \n",
       "4              279   1998   \n",
       "..              ...    ...  \n",
       "617            525   2020   \n",
       "618             50   2020   \n",
       "619              7   2020   \n",
       "620             16   2021   \n",
       "621              2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "UCI = pd.DataFrame()\n",
    "UCI['Name'] = Dataset_name\n",
    "UCI['Data type'] = Data_type\n",
    "UCI['Task'] = Task\n",
    "UCI['Attribute_type'] = Attribute_type\n",
    "UCI['No_of_instances'] = No_of_instances\n",
    "UCI['No_of_attribute'] = No_of_attribute\n",
    "UCI['Year'] = Year\n",
    "UCI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43bb166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f108b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5248312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
